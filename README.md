
<!--
<head>
  <h2>Background Image</h2>
    <style="background-image:url('gazeview.jpg'); background-size: cover; min-height: 500px; background-attachment: fixed; background-position: right top; background-repeat:no-repeat;"> 
    </style>
-->
<body>
<div class="background" style="background-image:url('gazeview.jpg'); background-size: cover; min-height: 500px; background-attachment: fixed; background-position: right top; background-repeat:no-repeat;"> 

<!--
<head>
<link href="format.css" type="text/css" rel="stylesheet" />    
</head>    
-->   

<!--
<style>
body{
background-image:url('gazeview.jpg'); 
  background-size: cover; 
  min-height: 500px; 
  background-attachment: fixed; 
  background-position: right top; 
  background-repeat:no-repeat;    
}
-->     

# Electrical and Computer Engineering, University of Thessaly, Greece

## Thesis :Gaze Estimation Algorithms using low cost Cameras



### Author: Christos Axelos



* Deep learning and particularly neural networks have offered a new point of view in problem 
solving. These techniques have been heavily adopted by many applications used in daily 
life or industry. Gaze estimation belongs to this category of applications. Since neural 
networks have been used in order to solve problems related to gaze estimation, they 
continuously provide solutions that outperform the previous ones.
This thesis proposes a neural network architecture based on the popular residual networks
(ResNets), a novel convolutional network introduced in ILSVRC [1] (2015). Specifically, 
the proposed method is a ResNet-20 network, which achieves competitive performance 
compared to the literature. This architecture achieves desirable performance regardless 
of the environmental conditions (in-the-wild) or the facial characteristics and it can also 
operate well without any calibration techniques.
Finally, this solution can substitute the use of expensive, special hardware when high 
accuracy is not necessary. As a result, reducing the production cost can make these 
applications accessible not only to specialized users, but to everyone with a laptop and a 
web camera.

* The paper of this Thesis can be found in greek here: https://194-177-202-67.uth.gr/xmlui/bitstream/handle/11615/52046/20167.pdf?sequence=1




<!--
</style>  
-->    
